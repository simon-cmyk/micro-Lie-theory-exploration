{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V. Landmark-based Localization and mapping. \n",
    "## Section A. Localization with error-state Kalman filter on manifold\n",
    "Based on the [paper](https://arxiv.org/abs/1812.01537) by Sola and [manifpy](https://artivis.github.io/manif/python/) examples. \n",
    "### This is hugely based on [se2_localization.py](examples/se2_localization.py), which we have not written ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from manifpy import SE2, SE2Tangent\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.linalg import inv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will not explain the code, since it is already well explained in the paper and the manifpy examples. We added some visualization to the code to help understand the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NUMBER_OF_LMKS_TO_MEASURE = 3\n",
    "\n",
    "X_simulation = SE2.Identity()\n",
    "X = SE2.Identity()\n",
    "X_unfiltered = SE2.Identity()\n",
    "P = np.zeros((3, 3))\n",
    "\n",
    "u_nom = np.array([0.1, 0.0, 0.05])\n",
    "u_sigmas = np.array([0.1, 0.1, 0.1])\n",
    "U = np.diagflat(np.square(u_sigmas))\n",
    "\n",
    "J_x = np.zeros((3, 3))\n",
    "J_u = np.zeros((3, 3))\n",
    "\n",
    "landmarks = np.array([\n",
    "    [2.0,  0.0],\n",
    "    [2.0,  1.0],\n",
    "    [2.0, -1.0]\n",
    "])\n",
    "\n",
    "measurements = [np.array([0, 0])] * NUMBER_OF_LMKS_TO_MEASURE\n",
    "\n",
    "y_sigmas = np.array([0.01, 0.01])\n",
    "R = np.diagflat(np.square(y_sigmas))\n",
    "\n",
    "J_xi_x = np.zeros((3, 3))\n",
    "J_e_xi = np.zeros((2, 3))\n",
    "\n",
    "X_sim = np.zeros((10, 3))\n",
    "X_est = np.zeros((10, 3))\n",
    "X_unf = np.zeros((10, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(10):\n",
    "        # I. Simulation\n",
    "\n",
    "        # simulate noise\n",
    "        u_noise = u_sigmas * np.random.rand(SE2.DoF)        # control noise\n",
    "        u_noisy = u_nom + u_noise                           # noisy control\n",
    "\n",
    "        u_simu = SE2Tangent(u_nom)\n",
    "        u_est = SE2Tangent(u_noisy)\n",
    "        u_unfilt = SE2Tangent(u_noisy)\n",
    "\n",
    "        # first we move\n",
    "        X_simulation = X_simulation + u_simu                # overloaded X.rplus(u) = X * exp(u)\n",
    "\n",
    "        # then we measure all landmarks\n",
    "        for i in range(NUMBER_OF_LMKS_TO_MEASURE):\n",
    "            b = landmarks[i]                                # lmk coordinates in world frame\n",
    "\n",
    "            # simulate noise\n",
    "            y_noise = y_sigmas * np.random.rand(SE2.Dim)    # measurement noise\n",
    "\n",
    "            y = X_simulation.inverse().act(b)               # landmark measurement, before adding noise\n",
    "\n",
    "            y = y + y_noise                                 # landmark measurement, noisy\n",
    "            measurements[i] = y                             # store for the estimator just below\n",
    "\n",
    "        # II. Estimation\n",
    "\n",
    "        # First we move\n",
    "\n",
    "        X = X.plus(u_est, J_x, J_u)                         # X * exp(u), with Jacobians\n",
    "\n",
    "        P = J_x @ P @ J_x.transpose() + J_u @ U @ J_u.transpose()\n",
    "\n",
    "        # Then we correct using the measurements of each lmk\n",
    "        for i in range(NUMBER_OF_LMKS_TO_MEASURE):\n",
    "            # landmark\n",
    "            b = landmarks[i]                                # lmk coordinates in world frame\n",
    "\n",
    "            # measurement\n",
    "            y = measurements[i]                             # lmk measurement, noisy\n",
    "\n",
    "            # expectation\n",
    "            e = X.inverse(J_xi_x).act(b, J_e_xi)            # note: e = R.tr * ( b - t ), for X = (R,t).\n",
    "            H = J_e_xi @ J_xi_x                             # Jacobian of the measurements wrt the robot pose. note: H = J_e_x = J_e_xi * J_xi_x\n",
    "            E = H @ P @ H.transpose()\n",
    "\n",
    "            # innovation\n",
    "            z = y - e\n",
    "            Z = E + R\n",
    "\n",
    "            # Kalman gain\n",
    "            K = P @ H.transpose() @ inv(Z)                  # K = P * H.tr * ( H * P * H.tr + R).inv\n",
    "\n",
    "            # Correction step\n",
    "            dx = K @ z                                      # dx is in the tangent space at X\n",
    "\n",
    "            # Update\n",
    "            X = X + SE2Tangent(dx)                          # overloaded X.rplus(dx) = X * exp(dx)\n",
    "            P = P - K @ Z @ K.transpose()\n",
    "\n",
    "        # III. Unfiltered\n",
    "\n",
    "        # move also an unfiltered version for comparison purposes\n",
    "        X_unfiltered = X_unfiltered + u_unfilt\n",
    "\n",
    "        # IV. Results\n",
    "\n",
    "        # Logging\n",
    "        X_sim[t, :] =  np.array([X_simulation.x(), X_simulation.y(), X_simulation.angle()])\n",
    "        X_est[t, :] =  np.array([X.x(), X.y(), X.angle()])\n",
    "        X_unf[t, :] =  np.array([X_unfiltered.x(), X_unfiltered.y(), X_unfiltered.angle()])\n",
    "        # END logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.title('W. landmarks')\n",
    "plt.scatter(X_sim[:, 0], X_sim[:, 1], color='k', label='simulated')\n",
    "plt.scatter(X_est[:, 0], X_est[:, 1], color='r', label='estimated')\n",
    "plt.scatter(X_unf[:, 0], X_unf[:, 1], color='b', label='unfiltered')\n",
    "plt.scatter(landmarks[:, 0], landmarks[:, 1], color='y', label='Landmarks')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.title('No landmarks')\n",
    "plt.scatter(X_sim[:, 0], X_sim[:, 1], color='k', label='simulated')\n",
    "plt.scatter(X_est[:, 0], X_est[:, 1], color='r', label='estimated')\n",
    "plt.scatter(X_unf[:, 0], X_unf[:, 1], color='b', label='unfiltered')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.title('Simulated vs estimated')\n",
    "plt.scatter(X_sim[:, 0], X_sim[:, 1], color='k', label='simulated')\n",
    "plt.scatter(X_est[:, 0], X_est[:, 1], color='r', label='estimated')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.title('Directions')\n",
    "plt.quiver(X_sim[:, 0], X_sim[:, 1], np.cos(X_sim[:, 2]), np.sin(X_sim[:, 2]), color='k', label='simulated')\n",
    "plt.quiver(X_est[:, 0], X_est[:, 1], np.cos(X_est[:, 2]), np.sin(X_est[:, 2]), color='r', label='estimated')\n",
    "plt.legend()\n",
    "plt.suptitle('Localization')\n",
    "plt.savefig(\"examples/localization_output.png\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lie_theory",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
